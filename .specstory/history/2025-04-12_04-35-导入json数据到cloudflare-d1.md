<!-- Generated by SpecStory -->

# 导入JSON数据到Cloudflare D1 (2025-04-12 12:35:37)

_**User**_

我有一份本地json文件是收入数据，我应该如何把这份json数据导入到cloudflare d1中？

---

_**Assistant**_

我来帮你解决如何将本地JSON数据导入到Cloudflare D1数据库中。根据你的Prisma schema，我看到你有一个`Income`模型，我们需要将JSON数据转换并导入到这个表中。

以下是具体的步骤：

1. 首先，你需要创建一个Node.js脚本来处理这个导入过程。这个脚本将：
   - 读取本地JSON文件
   - 使用Prisma Client连接数据库
   - 将数据导入到数据库中

这里是一个示例脚本：

```typescript
// import-income.ts
import { PrismaClient } from '@prisma/client'
import * as fs from 'fs'
import * as path from 'path'

const prisma = new PrismaClient()

async function importIncome() {
  try {
    // 读取JSON文件
    const jsonData = JSON.parse(
      fs.readFileSync(path.join(__dirname, 'your-income-data.json'), 'utf-8')
    )

    // 批量创建记录
    for (const item of jsonData) {
      await prisma.income.create({
        data: {
          owner: item.owner,
          time: item.time,
          baseSalary: parseFloat(item.baseSalary),
          overtimeMeal: parseFloat(item.overtimeMeal),
          housingFund: parseFloat(item.housingFund),
          leaveDeduction: parseFloat(item.leaveDeduction),
          housingFundDeduction: parseFloat(item.housingFundDeduction),
          medicalInsurance: parseFloat(item.medicalInsurance),
          pensionInsurance: parseFloat(item.pensionInsurance),
          unemploymentInsurance: parseFloat(item.unemploymentInsurance),
          tax: parseFloat(item.tax),
          rent: parseFloat(item.rent),
        },
      })
    }

    console.log('数据导入成功！')
  } catch (error) {
    console.error('导入出错：', error)
  } finally {
    await prisma.$disconnect()
  }
}

importIncome()
```

2. 在运行这个脚本之前，你需要：

   - 确保你的JSON数据格式与`Income`模型的结构相匹配
   - 设置正确的`DATABASE_URL`环境变量
   - 安装必要的依赖（`@prisma/client`）

3. 运行脚本前，需要先生成Prisma Client：
```bash
npx prisma generate
```

4. 然后运行导入脚本：
```bash
ts-node import-income.ts
```

注意事项：
1. 确保你的JSON数据中的字段名称与Prisma模型中的字段名称匹配
2. 所有数值字段（如`baseSalary`、`overtimeMeal`等）在JSON中即使是字符串形式，脚本中也会通过`parseFloat`转换为数值
3. 如果数据量较大，你可能需要考虑使用批量导入（`createMany`）来提高性能
4. 记得处理可能的错误情况，比如数据格式不正确等

如果你需要我帮你调整脚本以适应你的具体JSON数据格式，可以分享一下你的JSON数据的结构，我可以帮你调整脚本。

---

_**User**_

除了使用prisma的方式，有没有使用wrangler的方式呢

---

_**Assistant**_

是的，使用 Wrangler 确实是更直接的方法来将数据导入到 Cloudflare D1 数据库中。我看到你的项目中已经安装了 `wrangler@4.10.0`。

使用 Wrangler 导入数据的步骤如下：

1. 首先，你需要将 JSON 数据转换为 SQL 格式。基于你的 Prisma schema，我们可以创建一个 SQL 文件（比如 `income.sql`），内容类似这样：

```sql
INSERT INTO Income (id, owner, time, baseSalary, overtimeMeal, housingFund, leaveDeduction, housingFundDeduction, medicalInsurance, pensionInsurance, unemploymentInsurance, tax, rent, createdAt, updatedAt)
VALUES 
('uuid-1', '张三', '2024.03', 10000.0, 200.0, 1000.0, 0.0, 800.0, 200.0, 500.0, 100.0, 800.0, 2000.0, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
```

2. 然后你可以使用以下两种 Wrangler 方法导入数据：

方法一：使用 SQL 文件导入
```bash
npx wrangler d1 execute YOUR_DATABASE_NAME --file=./income.sql
```

方法二：直接导入 JSON 文件（需要先确保 JSON 格式正确）
```bash
npx wrangler d1 execute YOUR_DATABASE_NAME \
  --command="INSERT INTO Income SELECT * FROM json_each('$(cat your-data.json)')"
```

3. 如果你想要先将现有的 JSON 数据转换为 SQL，你可以创建一个简单的脚本（比如 `convert-json-to-sql.js`）：

```javascript
const fs = require('fs');
const { v4: uuidv4 } = require('uuid');

// 读取JSON文件
const jsonData = JSON.parse(fs.readFileSync('your-data.json', 'utf-8'));

// 生成SQL语句
const sqlStatements = jsonData.map(item => {
  return `INSERT INTO Income (
    id, 
    owner, 
    time, 
    baseSalary, 
    overtimeMeal, 
    housingFund, 
    leaveDeduction, 
    housingFundDeduction, 
    medicalInsurance, 
    pensionInsurance, 
    unemploymentInsurance, 
    tax, 
    rent, 
    createdAt, 
    updatedAt
  ) VALUES (
    '${uuidv4()}',
    '${item.owner}',
    '${item.time}',
    ${item.baseSalary},
    ${item.overtimeMeal},
    ${item.housingFund},
    ${item.leaveDeduction},
    ${item.housingFundDeduction},
    ${item.medicalInsurance},
    ${item.pensionInsurance},
    ${item.unemploymentInsurance},
    ${item.tax},
    ${item.rent},
    CURRENT_TIMESTAMP,
    CURRENT_TIMESTAMP
  );`
}).join('\n');

// 写入SQL文件
fs.writeFileSync('income.sql', sqlStatements);
```

4. 在执行导入之前，你可能还需要确保表已经创建：

```bash
# 创建表的SQL命令
npx wrangler d1 execute YOUR_DATABASE_NAME --command="
CREATE TABLE IF NOT EXISTS Income (
  id TEXT PRIMARY KEY,
  owner TEXT NOT NULL,
  time TEXT NOT NULL,
  baseSalary REAL NOT NULL,
  overtimeMeal REAL NOT NULL,
  housingFund REAL NOT NULL,
  leaveDeduction REAL NOT NULL,
  housingFundDeduction REAL NOT NULL,
  medicalInsurance REAL NOT NULL,
  pensionInsurance REAL NOT NULL,
  unemploymentInsurance REAL NOT NULL,
  tax REAL NOT NULL,
  rent REAL NOT NULL,
  createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,
  updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP
);"
```

5. 你还可以使用 Wrangler 验证数据是否导入成功：

```bash
# 查询导入的数据
npx wrangler d1 execute YOUR_DATABASE_NAME --command="SELECT * FROM Income;"
```

注意事项：
1. 记得替换 `YOUR_DATABASE_NAME` 为你实际的数据库名称
2. 在执行导入前，最好先在本地或测试环境中验证 SQL 语句的正确性
3. 如果数据量较大，可能需要分批导入
4. 确保 JSON 数据中的字符串不包含 SQL 注入风险的字符，最好做一下转义处理

如果你需要帮助处理具体的 JSON 数据格式，或者遇到任何问题，请随时告诉我。

---

_**User**_

详细说明方法二：直接导入 JSON 文件（需要先确保 JSON 格式正确）

---

_**Assistant**_

好的，我来详细说明如何使用 Wrangler 直接导入 JSON 文件到 D1 数据库。

假设你有一个 JSON 文件（例如 `income-data.json`），数据格式应该是这样的：

```json
[
  {
    "owner": "张三",
    "time": "2024.03",
    "baseSalary": 10000.0,
    "overtimeMeal": 200.0,
    "housingFund": 1000.0,
    "leaveDeduction": 0.0,
    "housingFundDeduction": 800.0,
    "medicalInsurance": 200.0,
    "pensionInsurance": 500.0,
    "unemploymentInsurance": 100.0,
    "tax": 800.0,
    "rent": 2000.0
  }
  // ... 更多数据
]
```

导入步骤如下：

1. 首先确保表已经创建：

```bash
npx wrangler d1 execute YOUR_DATABASE_NAME --command="
CREATE TABLE IF NOT EXISTS Income (
  id TEXT PRIMARY KEY,
  owner TEXT NOT NULL,
  time TEXT NOT NULL,
  baseSalary REAL NOT NULL,
  overtimeMeal REAL NOT NULL,
  housingFund REAL NOT NULL,
  leaveDeduction REAL NOT NULL,
  housingFundDeduction REAL NOT NULL,
  medicalInsurance REAL NOT NULL,
  pensionInsurance REAL NOT NULL,
  unemploymentInsurance REAL NOT NULL,
  tax REAL NOT NULL,
  rent REAL NOT NULL,
  createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,
  updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP
);"
```

2. 创建一个数据转换脚本（`prepare-json.js`），这个脚本会给数据添加必要的字段：

```javascript
const fs = require('fs');
const { v4: uuidv4 } = require('uuid');

// 读取原始JSON数据
const rawData = JSON.parse(fs.readFileSync('income-data.json', 'utf-8'));

// 处理数据：添加id和时间戳
const processedData = rawData.map(item => ({
  id: uuidv4(),
  ...item,
  createdAt: new Date().toISOString(),
  updatedAt: new Date().toISOString()
}));

// 将处理后的数据写入新文件
fs.writeFileSync('processed-income-data.json', JSON.stringify(processedData, null, 2));
```

3. 运行这个脚本来准备数据：

```bash
node prepare-json.js
```

4. 现在可以使用 Wrangler 导入数据。有两种方式：

方式一：直接从文件导入
```bash
npx wrangler d1 execute YOUR_DATABASE_NAME \
  --command="INSERT INTO Income SELECT * FROM json_each('$(cat processed-income-data.json)')"
```

方式二：如果数据量较大，可以分批导入：

```javascript
// batch-import.js
const fs = require('fs');
const { execSync } = require('child_process');

const data = JSON.parse(fs.readFileSync('processed-income-data.json', 'utf-8'));
const batchSize = 100; // 每批导入的数据量

for (let i = 0; i < data.length; i += batchSize) {
  const batch = data.slice(i, i + batchSize);
  const tempFile = `batch-${i}.json`;
  
  fs.writeFileSync(tempFile, JSON.stringify(batch));
  
  try {
    execSync(`npx wrangler d1 execute YOUR_DATABASE_NAME --command="INSERT INTO Income SELECT * FROM json_each('$(cat ${tempFile})')"`, { stdio: 'inherit' });
    console.log(`Successfully imported batch ${i / batchSize + 1}`);
  } catch (error) {
    console.error(`Error importing batch ${i / batchSize + 1}:`, error);
  } finally {
    fs.unlinkSync(tempFile); // 清理临时文件
  }
}
```

5. 验证数据是否导入成功：

```bash
# 检查总记录数
npx wrangler d1 execute YOUR_DATABASE_NAME --command="SELECT COUNT(*) FROM Income;"

# 查看部分数据
npx wrangler d1 execute YOUR_DATABASE_NAME --command="SELECT * FROM Income LIMIT 5;"
```

注意事项：

1. 确保 JSON 数据的字段名称与数据库表的列名完全匹配
2. 数值型字段（如 `baseSalary`、`tax` 等）在 JSON 中应该是数字而不是字符串
3. 如果 JSON 数据中包含特殊字符，需要进行适当的转义
4. 建议先在小数据集上测试，确保格式正确后再导入完整数据
5. 记得替换命令中的 `YOUR_DATABASE_NAME` 为你实际的数据库名称

如果你遇到任何问题，比如：
- JSON 格式不正确
- 数据类型不匹配
- 特殊字符处理
- 批量导入失败

都可以告诉我，我会帮你解决具体的问题。另外，如果你方便的话，可以分享一下你实际的 JSON 数据结构，这样我可以给出更具针对性的解决方案。

---

_**User**_

npx wrangler d1 execute YOUR_DATABASE_NAME \
  --command="INSERT INTO Income SELECT * FROM json_each('$(cat processed-income-data.json)')"，这句命令好像没有指定插入哪张表，只指定里数据库？

---

_**Assistant**_

在命令中我们已经指定了要插入的表 `INSERT INTO Income`，这里的 `Income` 就是表名。让我详细解释一下这个命令：

```bash
npx wrangler d1 execute an-monkey-db \
  --command="INSERT INTO Income SELECT * FROM json_each('$(cat processed-income-data.json)')"
```

这个命令可以拆解为：
1. `INSERT INTO Income` - 指定要插入数据的表名为 `Income`
2. `SELECT * FROM json_each(...)` - 从 JSON 数据中选择所有字段
3. `json_each('...')` - 这是 SQLite 的 JSON 函数，用于解析 JSON 数组中的每个对象

我看到你的 `wrangler.jsonc` 中数据库名称是 `an-monkey-db`，所以完整的命令应该是：

```bash
npx wrangler d1 execute an-monkey-db \
  --command="INSERT INTO Income (id, owner, time, baseSalary, overtimeMeal, housingFund, leaveDeduction, housingFundDeduction, medicalInsurance, pensionInsurance, unemploymentInsurance, tax, rent, createdAt, updatedAt) 
  SELECT 
    json_extract(value, '$.id'),
    json_extract(value, '$.owner'),
    json_extract(value, '$.time'),
    json_extract(value, '$.baseSalary'),
    json_extract(value, '$.overtimeMeal'),
    json_extract(value, '$.housingFund'),
    json_extract(value, '$.leaveDeduction'),
    json_extract(value, '$.housingFundDeduction'),
    json_extract(value, '$.medicalInsurance'),
    json_extract(value, '$.pensionInsurance'),
    json_extract(value, '$.unemploymentInsurance'),
    json_extract(value, '$.tax'),
    json_extract(value, '$.rent'),
    json_extract(value, '$.createdAt'),
    json_extract(value, '$.updatedAt')
  FROM json_each('$(cat processed-income-data.json)')"
```

这个更详细的命令：
1. 明确指定了要插入的列名
2. 使用 `json_extract` 来确保每个字段的值正确对应到相应的列
3. 可以更好地处理数据类型的匹配

这样可以确保：
- 数据被插入到正确的表中
- 每个字段的值都正确对应
- 避免可能的数据类型不匹配问题

你可以先用一小部分数据测试一下这个命令，确保一切正常后再导入完整的数据集。

---

_**User**_



---

_**Assistant**_

看到错误信息了，这个错误表明提供的值的数量（8个）与表中的列数（15个）不匹配。让我们看看你的 JSON 数据结构可能是什么样的。

为了解决这个问题，我们需要确保 SQL 命令中指定的列与提供的值一一对应。让我们尝试先看看你的 JSON 数据的结构：

```bash
# 首先查看 JSON 文件的内容
cat processed-income-data.json
```

或者，我们可以先用这个命令来查看表结构：

```bash
npx wrangler d1 execute an-monkey-db --command="PRAGMA table_info(Income);"
```

这样我们就能看到具体的表结构，然后根据你的实际 JSON 数据结构来修改导入命令。

如果你方便的话，可以分享一下你的 JSON 数据的一个示例，这样我可以帮你写出完全匹配的导入命令。不过，基于之前的错误信息，看起来你的 JSON 数据可能只包含了 8 个字段，而不是表中定义的全部 15 个字段。

我们需要确保：
1. 所有必需字段都有值
2. 可选字段如果没有值，需要提供默认值
3. ID 和时间戳字段需要正确处理

你能分享一下你的 JSON 数据的结构吗？这样我可以给出更精确的解决方案。

---

